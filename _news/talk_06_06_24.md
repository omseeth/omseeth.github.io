---
layout: post
date: 2024-06-06 13:00:00-0400
inline: true
related_posts: false
---

In my 45 minutes presentation, I discussed at [Deutsche Telekom's AI Competence Center](https://www.telekom.com/en/company/digital-responsibility/details/artificial-intelligence-at-deutsche-telekom-1055154) LLMs and the possibility of lying.
\\
**Title**: When Moral Rules Reach their Limits: Should LLMs Lie?
\\
**Abstract**: One of the most famous ideas in philosophy is Immanuel Kant's categorical imperative: "Act only according to that maxim whereby you can at the same time will that it should become a universal law." This imperative gives us a concrete solution as to how to act morally. It allows us to define ethical rules from non-ethical ones. At the same time, Kant is also known for proposing that to not lie should be such a binding moral rule. However, we encounter many situations where humans lie, and also some where lying appears even ethically licensed. If so, following a rule such as to not lie does not seem to be always what we want from an ethical point of view. If we, as humans, allow degrees of variabilities to truth-telling, what does that mean if we try to "teach" an LLM to only produce true and factual content?
