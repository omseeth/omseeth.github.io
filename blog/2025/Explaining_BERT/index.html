<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Explaining BERT-based hate speech detection with LIME and Saliency using Captum | Maximilian Seeth </title> <meta name="author" content="Maximilian Seeth"> <meta name="description" content="Tutorial with full code"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%9A&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://omseeth.github.io/blog/2025/Explaining_BERT/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Maximilian</span> Seeth </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Explaining BERT-based hate speech detection with LIME and Saliency using Captum</h1> <p class="post-meta"> Created in March 19, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/bert"> <i class="fa-solid fa-hashtag fa-sm"></i> BERT</a>   <a href="/blog/tag/lime"> <i class="fa-solid fa-hashtag fa-sm"></i> LIME</a>   <a href="/blog/tag/saliency"> <i class="fa-solid fa-hashtag fa-sm"></i> Saliency</a>   <a href="/blog/tag/captum"> <i class="fa-solid fa-hashtag fa-sm"></i> captum</a>   <a href="/blog/tag/pytorch"> <i class="fa-solid fa-hashtag fa-sm"></i> PyTorch</a>   <a href="/blog/tag/explainable"> <i class="fa-solid fa-hashtag fa-sm"></i> explainable</a>   <a href="/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> AI</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>It has been shown that BERT’s domain-specific fine-tuning approaches for hate speech detection are still competitive for hate speech classification (Roy et al., 2023). Although LLMs can also be used for classification tasks, they are trained on a wider domain of tasks and more data. Their predictive power is also tied to the right model instructions and decoding strategies. Roy et al. (2023) confirm that LLMs are sensitive to input variations and struggle in particular with implicit cases of hate speech. This aspect makes it also more difficult to probe LLMs with explainability methods. In contrast, BERT models, as classifiers, are easier to explain.</p> <p>This notebook’s idea is to investigate how well BERT-based hate speech detection is aligned with human judgments of German hate speech. To arrive at plausible explanations, we also need to determine which method, that is, a model agnostic simplification such as LIME or a gradient-based method such as Saliency, works best for our purpose.</p> <p>As we can see in the following example, the explainability methods will tell us which tokens influenced BERT’s prediction.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Explaining_BERT/visualization_example_1-480.webp 480w,/assets/img/Explaining_BERT/visualization_example_1-800.webp 800w,/assets/img/Explaining_BERT/visualization_example_1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/Explaining_BERT/visualization_example_1.png" class="img-fluid mx-auto d-block" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="overview">Overview</h3> <ul> <li>Loading and preprocessing Gaze4Hate dataset</li> <li>Loading and initializing the BERT model for hate speech detection</li> <li>Deriving explanations through attributions from BERT with LIME</li> <li>Deriving explanations through attributions from BERT with Saliency</li> <li>Evaluating the results (human vs. BERT rationales)</li> <li>Visualizing the results (alignment)</li> </ul> <p>Before we start, let us begin with installing and loading libraries, which we will use later in the project.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">pandas</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">numpy</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">seaborn</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">scipy</span>

<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">transformers</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">torch</span> <span class="n">torchvision</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">U</span> <span class="n">scikit</span><span class="o">-</span><span class="n">learn</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">openpyxl</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">captum</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">sentencepiece</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">ipywidgets</span>

<span class="err">!</span><span class="n">pip</span> <span class="n">show</span> <span class="n">transformers</span>
</code></pre></div></div> <p>We’ll need the following packages</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Basic libraries
</span><span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="n">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span><span class="p">,</span> <span class="n">display</span>
<span class="kn">import</span> <span class="n">json</span>
<span class="kn">from</span> <span class="n">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">requests</span>
<span class="kn">import</span> <span class="n">sys</span>

<span class="c1"># Colab
# from google.colab import drive
</span>
<span class="c1"># Data libraries
</span><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sn</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Deeplearning libraries
</span><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
<span class="kn">from</span> <span class="n">captum.attr</span> <span class="kn">import</span> <span class="n">LimeBase</span><span class="p">,</span> <span class="n">Saliency</span>
<span class="kn">from</span> <span class="n">captum._utils.models.linear_model</span> <span class="kn">import</span> <span class="n">SkLearnLasso</span>

<span class="c1"># Evaluation libraries
</span><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span>
<span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">pearsonr</span>
</code></pre></div></div> <h2 id="loading-and-preprocessing-gaze4hate-dataset">Loading and preprocessing Gaze4Hate dataset</h2> <p>We use the GAZE4HATE dataset from Alacam et al. (2024), which consists of “hatefulness ratings of text w.r.t. gender, eye movements during plain readings of the statements” (Alacam et al., 2024, p.189) from 43 participants (32 female, 10 male, 1 non-binary, Mean age = 23.5, SD = 5.3 as reported in (Alacam et al., 2024)). The participants’ ratings were gathered on a Likert scale from 1 to 7, where 1 corresponded to ‘very positive’ and 7 to ‘extremely hateful’. 4 and 5 were considered as ‘neutral’ and ‘mean’. The data comes with rationales for the participants’ judgments. These rationales were collected through clicks on words that the participants found relevant. Conversely, if a word is not clicked, it is not considered a determining factor. Finally, the participants’ response were assigned to two hate annotations: the first measured the answers along the binary levels of ‘hate’ and ‘no-hate’ and the second along three levels, namely ‘hate’, ‘neutral’, and ‘positive’. All participants saw all sentences in the data set.</p> <p>In this project, we are interested in the explicit rationales, which we will later compare with BERT’s attributions with respect to the words that influenced its predictions.</p> <p>We can find and download the dataset under a CC-BY-NC 4.0 license from: <a href="https://osf.io/fgdjw" rel="external nofollow noopener" target="_blank">https://osf.io/fgdjw</a></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># URL of the CSV file
</span><span class="n">url</span> <span class="o">=</span> <span class="sh">"</span><span class="s">https://osf.io/download/fgdjw/</span><span class="sh">"</span>

<span class="c1"># Downloading the file
</span><span class="k">try</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="k">except</span> <span class="n">requests</span><span class="p">.</span><span class="nb">ConnectionError</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">No internet connection</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Saving it as a local CSV file
</span><span class="n">filename</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Gaze4Hate.csv</span><span class="sh">"</span>
<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="sh">"</span><span class="s">wb</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
    <span class="nb">file</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="n">response</span><span class="p">.</span><span class="n">content</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">File downloaded and saved as </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">File</span> <span class="n">downloaded</span> <span class="ow">and</span> <span class="n">saved</span> <span class="k">as</span> <span class="n">Gaze4Hate</span><span class="p">.</span><span class="n">csv</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">os</span><span class="p">.</span><span class="nf">chdir</span><span class="p">(</span><span class="sh">"</span><span class="s">/path</span><span class="sh">"</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">Gaze4Hate.csv</span><span class="sh">"</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="sh">"</span><span class="se">\t</span><span class="sh">"</span><span class="p">)</span>

<span class="sh">"""</span><span class="s">
# Mount Google Drive
drive.mount(</span><span class="sh">'</span><span class="s">/content/gdrive</span><span class="sh">'</span><span class="s">)

PATH = r</span><span class="sh">"</span><span class="s">/content/gdrive/My Drive/Colab Notebooks/EXPL_LIME</span><span class="sh">"</span><span class="s">
os.chdir(PATH)

directory = os.getcwd()
df = pd.read_csv(</span><span class="sh">"</span><span class="s">Gaze4Hate_data.csv</span><span class="sh">"</span><span class="s">, delimiter=</span><span class="sh">"</span><span class="se">\t</span><span class="sh">"</span><span class="s">)</span><span class="sh">"</span><span class="s">
</span><span class="sh">"""</span>
</code></pre></div></div> <p>Let’s inspect the raw dataset.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">pno</span><span class="sh">"</span><span class="p">]</span> <span class="o">==</span> <span class="sh">"</span><span class="s">p1</span><span class="sh">"</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">sno</span><span class="sh">"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">19</span><span class="p">)]</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Explaining_BERT/Gaze4Hate_data-480.webp 480w,/assets/img/Explaining_BERT/Gaze4Hate_data-800.webp 800w,/assets/img/Explaining_BERT/Gaze4Hate_data-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/Explaining_BERT/Gaze4Hate_data.png" class="img-fluid mx-auto d-block" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>We have many columns with different data, including the sentences, the participants’ hate ratings in terms of gaze data, and click data. Let’s look an example:</p> <p><code class="language-plaintext highlighter-rouge">Frauen gehören in die Küche.</code></p> <p>Which translates to:</p> <p><code class="language-plaintext highlighter-rouge">Women belong in the kitchen.</code></p> <p>The experiment’s first subject clicked on the tokens: “Frauen” and “Küche” (see column <code class="language-plaintext highlighter-rouge">Clicked</code>) to justify her judgement of the sentence, which was ‘hate’. Since the dataset has 35 columns they might not all be displayed in your IDE and you won’t see all columns right away.</p> <p>Let’s select the columns and rows from the dataset that we need for our project. We also want to create a list of the experiment’s unique sentences that we can use to make predictions with our models.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rationale_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="sh">"</span><span class="s">pno</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">assertion</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">sno</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">IA_LABEL</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Clicked</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Intensity_Category_Binary</span><span class="sh">"</span><span class="p">]]</span>

<span class="n">experiment_sents</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">sent</span><span class="p">,</span> <span class="n">sno</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">rationale_df</span><span class="p">[</span><span class="sh">"</span><span class="s">assertion</span><span class="sh">"</span><span class="p">],</span><span class="n">rationale_df</span><span class="p">[</span><span class="sh">"</span><span class="s">sno</span><span class="sh">"</span><span class="p">]):</span>
    <span class="n">experiment_sents</span><span class="p">.</span><span class="nf">update</span><span class="p">({</span><span class="n">sno</span><span class="p">:</span> <span class="n">sent</span><span class="p">})</span>

<span class="n">experiment_sents</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span><span class="nf">sorted</span><span class="p">(</span><span class="n">experiment_sents</span><span class="p">.</span><span class="nf">items</span><span class="p">()))</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">experiment_sents</span><span class="p">))</span>  <span class="c1"># The dataset contains 90 sentences
</span><span class="nf">print</span><span class="p">(</span><span class="n">experiment_sents</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">90</span>
<span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="sh">'</span><span class="s">Frauen haben einen signifikant geringeren Durchsetzungswillen.</span><span class="sh">'</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="sh">'</span><span class="s">Frauen sind psychisch nicht für komplexe Arbeit geschaffen.</span><span class="sh">'</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="p">...}</span>
</code></pre></div></div> <p>From the human annotation, we want to have the average rationales for the sentences that were judged as hateful or non-hateful.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">participants_n</span> <span class="o">=</span> <span class="mi">43</span>
<span class="n">human_hate_rationale</span> <span class="o">=</span> <span class="nf">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="nf">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span>
<span class="n">human_no_hate_rationale</span> <span class="o">=</span> <span class="nf">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="nf">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span>

<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">rationale_df</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
    <span class="n">sentence_num</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="sh">"</span><span class="s">sno</span><span class="sh">"</span><span class="p">]</span>
    <span class="n">word</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="sh">"</span><span class="s">IA_LABEL</span><span class="sh">"</span><span class="p">]</span>
    <span class="n">clicked</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="sh">"</span><span class="s">Clicked</span><span class="sh">"</span><span class="p">]</span>
    <span class="n">category</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="sh">"</span><span class="s">Intensity_Category_Binary</span><span class="sh">"</span><span class="p">]</span>

    <span class="c1"># Selecting the rationales from those judgments which labeled the given sentence as hate
</span>    <span class="k">if</span> <span class="n">category</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">clicked</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">human_hate_rationale</span><span class="p">[</span><span class="n">sentence_num</span><span class="p">][</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">human_hate_rationale</span><span class="p">[</span><span class="n">sentence_num</span><span class="p">][</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">clicked</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">human_no_hate_rationale</span><span class="p">[</span><span class="n">sentence_num</span><span class="p">][</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">human_no_hate_rationale</span><span class="p">[</span><span class="n">sentence_num</span><span class="p">][</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">0</span>

<span class="c1"># We average the responses by the number of participants
</span><span class="n">average_human_hate_rationales</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">sentence_num</span><span class="p">:</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="n">count</span> <span class="o">/</span> <span class="mi">43</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">words</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span>
    <span class="k">for</span> <span class="n">sentence_num</span><span class="p">,</span> <span class="n">words</span> <span class="ow">in</span> <span class="n">human_hate_rationale</span><span class="p">.</span><span class="nf">items</span><span class="p">()</span>
<span class="p">}</span>

<span class="n">average_human_hate_rationales</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span><span class="nf">sorted</span><span class="p">(</span><span class="n">average_human_hate_rationales</span><span class="p">.</span><span class="nf">items</span><span class="p">()))</span>    
<span class="nf">print</span><span class="p">(</span><span class="n">average_human_hate_rationales</span><span class="p">)</span>

<span class="n">average_human_no_hate_rationales</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">sentence_num</span><span class="p">:</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="n">count</span> <span class="o">/</span> <span class="mi">43</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">words</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span>
    <span class="k">for</span> <span class="n">sentence_num</span><span class="p">,</span> <span class="n">words</span> <span class="ow">in</span> <span class="n">human_no_hate_rationale</span><span class="p">.</span><span class="nf">items</span><span class="p">()</span>
<span class="p">}</span>

<span class="n">average_human_no_hate_rationales</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span><span class="nf">sorted</span><span class="p">(</span><span class="n">average_human_no_hate_rationales</span><span class="p">.</span><span class="nf">items</span><span class="p">()))</span>      
<span class="nf">print</span><span class="p">(</span><span class="n">average_human_no_hate_rationales</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="p">{</span><span class="sh">'</span><span class="s">Word 1</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.37209302325581395</span><span class="p">,</span> <span class="sh">'</span><span class="s">Word 2</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.11627906976744186</span><span class="p">,</span> <span class="sh">'</span><span class="s">Word 3</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.023255813953488372</span><span class="p">,</span> <span class="sh">'</span><span class="s">Word 4</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.5116279069767442</span><span class="p">,</span> <span class="sh">'</span><span class="s">Word 5</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.7674418604651163</span><span class="p">,</span> <span class="sh">'</span><span class="s">Word 6</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.6511627906976745</span><span class="p">},</span> <span class="p">...}</span>
<span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="p">{</span><span class="sh">'</span><span class="s">Word 1</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.046511627906976744</span><span class="p">,</span> <span class="sh">'</span><span class="s">Word 2</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="sh">'</span><span class="s">Word 3</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="sh">'</span><span class="s">Word 4</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.09302325581395349</span><span class="p">,</span> <span class="sh">'</span><span class="s">Word 5</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.09302325581395349</span><span class="p">,</span> <span class="sh">'</span><span class="s">Word 6</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.09302325581395349</span><span class="p">},</span> <span class="p">...}</span>
</code></pre></div></div> <p>We can see that not all sentences have received rationales, some were univocally annotated as hateful:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">average_human_no_hate_rationales</span><span class="p">))</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">82</span>
</code></pre></div></div> <p>Futhermore, we want to derive labels for the sentences from the human judgments on average. We select a subframge with only the participants (see column <code class="language-plaintext highlighter-rouge">RECORDING_SESSION_LABEL</code>) and judgments (see column <code class="language-plaintext highlighter-rouge">Intensity_Category_Binary</code>) for each respective sentence (see column <code class="language-plaintext highlighter-rouge">sno</code>).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">judgment_df</span> <span class="o">=</span> <span class="n">rationale_df</span><span class="p">[[</span><span class="sh">"</span><span class="s">pno</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">sno</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Intensity_Category_Binary</span><span class="sh">"</span><span class="p">]]</span>

<span class="c1"># We can drop all duplicates
</span><span class="n">judgment_df</span> <span class="o">=</span> <span class="n">judgment_df</span><span class="p">.</span><span class="nf">drop_duplicates</span><span class="p">()</span>

<span class="c1"># 90 (sentences) * 43 (participants) = 3870 (judgments); as of 19.03.2025 we report 3616 judgments from the dataset which indicates that some are missing
</span><span class="nf">print</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">judgment_df</span><span class="p">))</span>

<span class="n">human_labels</span> <span class="o">=</span> <span class="nf">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
<span class="n">avg_human_labels</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">judgment_df</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
    <span class="n">sno</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="sh">"</span><span class="s">sno</span><span class="sh">"</span><span class="p">]</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="sh">"</span><span class="s">Intensity_Category_Binary</span><span class="sh">"</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">human_labels</span><span class="p">[</span><span class="n">sno</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">human_labels</span><span class="p">[</span><span class="n">sno</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">human_labels</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span><span class="nf">sorted</span><span class="p">(</span><span class="n">human_labels</span><span class="p">.</span><span class="nf">items</span><span class="p">()))</span> 

<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">judgments</span> <span class="ow">in</span> <span class="n">human_labels</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
    <span class="n">count</span> <span class="o">=</span> <span class="nc">Counter</span><span class="p">(</span><span class="n">judgments</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">count</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">count</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="n">avg_human_labels</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">count</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">count</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="n">avg_human_labels</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">avg_human_labels</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="n">avg_human_labels</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">3616</span>
<span class="mi">90</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
</code></pre></div></div> <h2 id="loading-and-initializing-the-bert-model">Loading and initializing the BERT model</h2> <p>Having prepared our data to make comparisons between the annotators’ rationales and the model’s attributions, we can now intialize our BERT model.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">backends</span><span class="p">.</span><span class="n">mps</span><span class="p">.</span><span class="nf">is_built</span><span class="p">():</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">"</span><span class="s">mps</span><span class="sh">"</span><span class="p">)</span>  <span class="c1"># For mac use
</span><span class="k">elif</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">():</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">BERT_tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">deepset/bert-base-german-cased-hatespeech-GermEval18Coarse</span><span class="sh">"</span><span class="p">)</span>

<span class="n">BERT</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">deepset/bert-base-german-cased-hatespeech-GermEval18Coarse</span><span class="sh">"</span><span class="p">,</span> 
    <span class="n">output_hidden_states</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
    <span class="n">return_dict</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
    <span class="n">output_attentions</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">BERT</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span> 

<span class="c1"># We can derive the classes used in the model as follows
</span><span class="n">classes</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">BERT</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">id2label</span><span class="p">.</span><span class="nf">keys</span><span class="p">())</span>

<span class="nf">print</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span>  <span class="c1"># 1 for "hate" and 0 for "no-hate"  
</span></code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
</code></pre></div></div> <p>For our model’s predictions, we need to define a few BERT specificities, such as the encodings that the model will use for its predictions.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">encodings</span> <span class="o">=</span> <span class="p">[</span><span class="n">BERT_tokenizer</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span> <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">experiment_sents</span><span class="p">.</span><span class="nf">values</span><span class="p">()]</span>
</code></pre></div></div> <p>We can define a function to make predictions from a given BERT model. We should assure that this function only takes a single argument for the encodings and handles the masking necessary for BERT internally because our Captum LIME class that we will use later passes a single input to its perturbation.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">encoding</span><span class="p">):</span>
    <span class="c1"># Converting masks and encodings to integers is necessary when using LIME
</span>    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">encoding</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">).</span><span class="nf">long</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="nc">BERT</span><span class="p">(</span><span class="n">encoding</span><span class="p">.</span><span class="nf">long</span><span class="p">(),</span> <span class="n">mask</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">output</span><span class="p">.</span><span class="n">logits</span>
</code></pre></div></div> <p>The predictions from the encodings can be realized through a loop. We’ll have to transform each encoding into a PyTorch tensor. We also need to add another dimension here (see <code class="language-plaintext highlighter-rouge">.unsqueeze(0)</code>).</p> <p>Usually, it is best practice to let the model make several rounds of predictions and average over the results. For simplicity, we will just do a single round.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">logits</span> <span class="o">=</span> <span class="p">[</span><span class="nf">predict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">sent</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span> <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">encodings</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sh">"</span><span class="s">Processing</span><span class="sh">"</span><span class="p">)]</span>
    <span class="c1"># Selecting the label with highest probability
</span>
<span class="n">BERT_predictions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">logit</span> <span class="ow">in</span> <span class="n">logits</span><span class="p">:</span>
    <span class="n">pred_id</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">logit</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">item</span><span class="p">()</span>
    <span class="n">BERT_predictions</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">pred_id</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">BERT_predictions</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="n">BERT_predictions</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">90</span>
<span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
</code></pre></div></div> <p>We can now make a comparison of the model’s predictions with the human judgments.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="nf">classification_report</span><span class="p">(</span><span class="n">avg_human_labels</span><span class="p">,</span> <span class="n">BERT_predictions</span><span class="p">))</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">precision</span>    <span class="n">recall</span>  <span class="n">f1</span><span class="o">-</span><span class="n">score</span>   <span class="n">support</span>

           <span class="mi">0</span>       <span class="mf">0.66</span>      <span class="mf">0.84</span>      <span class="mf">0.74</span>        <span class="mi">50</span>
           <span class="mi">1</span>       <span class="mf">0.69</span>      <span class="mf">0.45</span>      <span class="mf">0.55</span>        <span class="mi">40</span>

    <span class="n">accuracy</span>                           <span class="mf">0.67</span>        <span class="mi">90</span>
   <span class="n">macro</span> <span class="n">avg</span>       <span class="mf">0.67</span>      <span class="mf">0.65</span>      <span class="mf">0.64</span>        <span class="mi">90</span>
<span class="n">weighted</span> <span class="n">avg</span>       <span class="mf">0.67</span>      <span class="mf">0.67</span>      <span class="mf">0.65</span>        <span class="mi">90</span>
</code></pre></div></div> <p>From here on we would like to understand on what basis, that is, due to which tokens BERT made its predictions. Before we move on, let us have a quick look at how the BERT model would embed a given example sentence.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.0094</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0187</span><span class="p">,</span>  <span class="mf">0.0148</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mf">0.0247</span><span class="p">,</span>  <span class="mf">0.0179</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0125</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0353</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0224</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0362</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mf">0.0270</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0264</span><span class="p">,</span>  <span class="mf">0.0183</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0400</span><span class="p">,</span>  <span class="mf">0.0027</span><span class="p">,</span>  <span class="mf">0.0385</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mf">0.0340</span><span class="p">,</span>  <span class="mf">0.0006</span><span class="p">,</span>  <span class="mf">0.0448</span><span class="p">],</span>
        <span class="p">...,</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0541</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0053</span><span class="p">,</span>  <span class="mf">0.0424</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mf">0.0058</span><span class="p">,</span>  <span class="mf">0.0142</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0847</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0010</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0685</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0209</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">0.0086</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0345</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0202</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0009</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0561</span><span class="p">,</span>  <span class="mf">0.0226</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">0.0176</span><span class="p">,</span>  <span class="mf">0.0209</span><span class="p">,</span>  <span class="mf">0.0158</span><span class="p">]],</span>
       <span class="n">device</span><span class="o">=</span><span class="sh">'</span><span class="s">mps:0</span><span class="sh">'</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="nc">Size</span><span class="p">([</span><span class="mi">13</span><span class="p">,</span> <span class="mi">768</span><span class="p">])</span>
</code></pre></div></div> <h2 id="deriving-explanations-through-attributions-with-lime">Deriving explanations through attributions with LIME</h2> <p>LIME analyzes how changes to the input affect the model’s predictions. It creates a local linear approximation for each instance by making small modifications to the input and observing the resulting changes in output. The weights from this linear model indicate the importance of each token, serving as saliency scores. The original paper (Ribeiro et al. 2016) introducing LIME can be found here: <a href="https://dl.acm.org/doi/10.1145/2939672.2939778" rel="external nofollow noopener" target="_blank">https://dl.acm.org/doi/10.1145/2939672.2939778</a>.</p> <p>In this part of the project, we will make use of the <a href="https://captum.ai" rel="external nofollow noopener" target="_blank">Captum</a> library to investigate how the BERT model made its predictions. Captum is built on PyTorch and an excellent library for many explainability methods in machine learning. As we want to implement LIME for text, the following approach is built upon the Captum <a href="https://captum.ai/tutorials/Image_and_Text_Classification_LIME" rel="external nofollow noopener" target="_blank">tutorial</a> for LIME. For analyzing texts, we need to use the LimeBase version. The documentation can be found here: <a href="https://captum.ai/api/lime.html" rel="external nofollow noopener" target="_blank">https://captum.ai/api/lime.html</a>.</p> <p>Captum’s LimeBase requires to define several parts of the LIME approach manually. We shall start with this.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Encode text indices into latent representations &amp; calculate cosine similarity
</span><span class="k">def</span> <span class="nf">exp_embedding_cosine_distance</span><span class="p">(</span><span class="n">original_inp</span><span class="p">,</span> <span class="n">perturbed_inp</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    
    <span class="n">original_inp</span> <span class="o">=</span> <span class="n">original_inp</span><span class="p">.</span><span class="nf">long</span><span class="p">()</span>
    <span class="n">perturbed_inp</span> <span class="o">=</span> <span class="n">perturbed_inp</span><span class="p">.</span><span class="nf">long</span><span class="p">()</span>

    <span class="c1"># We want to compare the BERT embeddings from the final hidden states and use their mean
</span>    <span class="c1"># LIME will ablate some of the input tokens and the left over is perturbed_inp; we embed this with our BERT model and make a comparison through cosine similarity with the original embedded input
</span>
    <span class="c1"># The model internally adds position embeddings based on the input length and assumes a default sequence starting from position 0 
</span>    <span class="n">original_emb</span> <span class="o">=</span> <span class="n">BERT</span><span class="p">.</span><span class="n">bert</span><span class="p">.</span><span class="nf">embeddings</span><span class="p">(</span><span class="n">original_inp</span><span class="p">,</span> <span class="bp">None</span><span class="p">).</span><span class="nf">mean</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">perturbed_emb</span> <span class="o">=</span> <span class="n">BERT</span><span class="p">.</span><span class="n">bert</span><span class="p">.</span><span class="nf">embeddings</span><span class="p">(</span><span class="n">perturbed_inp</span><span class="p">,</span> <span class="bp">None</span><span class="p">).</span><span class="nf">mean</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">distance</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">F</span><span class="p">.</span><span class="nf">cosine_similarity</span><span class="p">(</span><span class="n">original_emb</span><span class="p">,</span> <span class="n">perturbed_emb</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">distance</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># One hot encoding for masking tokens randomly for ablation
</span><span class="k">def</span> <span class="nf">bernoulli_perturb</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones_like</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>  <span class="c1"># Amount of masked tokens
</span>    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">bernoulli</span><span class="p">(</span><span class="n">probs</span><span class="p">).</span><span class="nf">long</span><span class="p">()</span>

    <span class="c1"># Ensuring at least one token remains (by forcing the first token to stay) because the BERT model expects an input of at least one token
</span>    <span class="k">if</span> <span class="n">mask</span><span class="p">.</span><span class="nf">sum</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">mask</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">mask</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,))]</span> <span class="o">=</span> <span class="mi">1</span>  

    <span class="k">return</span> <span class="n">mask</span>

<span class="c1"># Removing absent token based on the intepretable representation sample
</span><span class="k">def</span> <span class="nf">interp_to_input</span><span class="p">(</span><span class="n">interp_sample</span><span class="p">,</span> <span class="n">original_input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">original_input</span><span class="p">[</span><span class="n">interp_sample</span><span class="p">.</span><span class="nf">bool</span><span class="p">()].</span><span class="nf">view</span><span class="p">(</span><span class="n">original_input</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Captum's customizable Lime class
</span><span class="n">LIME</span> <span class="o">=</span> <span class="nc">LimeBase</span><span class="p">(</span>
    <span class="n">predict</span><span class="p">,</span>
    <span class="n">interpretable_model</span><span class="o">=</span><span class="nc">SkLearnLasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.08</span><span class="p">),</span>
    <span class="n">similarity_func</span><span class="o">=</span><span class="n">exp_embedding_cosine_distance</span><span class="p">,</span>
    <span class="n">perturb_func</span><span class="o">=</span><span class="n">bernoulli_perturb</span><span class="p">,</span>
    <span class="n">perturb_interpretable_space</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">from_interp_rep_transform</span><span class="o">=</span><span class="n">interp_to_input</span><span class="p">,</span>
    <span class="n">to_interp_rep_transform</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</code></pre></div></div> <p>Everything is in place to loop through the data’s hateful and non-hateful sentences, deriving attributions with our custom LimeBase class.</p> <p>The parameter <code class="language-plaintext highlighter-rouge">show_progress</code> is a widget that might not work in all IDEs right away; I had to adjust my vscode settings.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Saving all attributions to this list for later comparisons
</span><span class="n">LIME_attributions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">encoding</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">encodings</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sh">"</span><span class="s">Processing</span><span class="sh">"</span><span class="p">):</span>
    <span class="n">attrs</span> <span class="o">=</span> <span class="n">LIME</span><span class="p">.</span><span class="nf">attribute</span><span class="p">(</span>
        <span class="n">torch</span><span class="p">.</span><span class="nc">Tensor</span><span class="p">(</span><span class="n">encoding</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="c1"># Adding batch dimension for Captum
</span>        <span class="n">target</span><span class="o">=</span><span class="n">BERT_predictions</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
        <span class="n">n_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>  <span class="c1"># This is a hyperparameter that turned out to work well when set to 200 for our task
</span>        <span class="n">show_progress</span><span class="o">=</span><span class="bp">False</span>  <span class="c1"># vscode is not properly showing progress, must edit vscode's settings.json for widgets (add: "jupyter.widgetScriptSources": ["jsdelivr.com", "unpkg.com"]); if problems persist, set to False
</span>    <span class="p">).</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">LIME_attributions</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">attrs</span><span class="p">.</span><span class="nf">tolist</span><span class="p">())</span>
    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></div> <p>We can have a look at the attributions:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="n">LIME_attributions</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[[</span><span class="o">-</span><span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2673813998699188</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.16184958815574646</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0753924623131752</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.2013273388147354</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.452242910861969</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0483330637216568</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.11272305995225906</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.14384473860263824</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">...]</span>
</code></pre></div></div> <p>The original data collection from Alacam et al. (2024) contained instances that were later dropped. This led to unique sentence numbers from 1 to 93. To avoid mismatches with the human rationales for given sentences, we should create a list of the actual sentence numbers from the experiment.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">unique_sentence_num</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">sorted</span><span class="p">(</span><span class="n">experiment_sents</span><span class="p">.</span><span class="nf">keys</span><span class="p">()))</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">unique_sentence_num</span><span class="p">))</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">90</span>
</code></pre></div></div> <p>Let’s save the attributions together with their unique ids and sentences so we can later load them for our evaluation with respect to the human rationales.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">BERT_LIME_attributions</span> <span class="o">=</span> <span class="p">{}</span>

<span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">BERT_tokenizer</span><span class="p">.</span><span class="nf">convert_ids_to_tokens</span><span class="p">(</span><span class="n">encoding</span><span class="p">)</span> <span class="k">for</span> <span class="n">encoding</span> <span class="ow">in</span> <span class="n">encodings</span><span class="p">]</span>

<span class="k">for</span> <span class="n">sent</span><span class="p">,</span> <span class="n">attr</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">LIME_attributions</span><span class="p">):</span>
    <span class="n">BERT_LIME_attributions</span><span class="p">[</span><span class="n">unique_sentence_num</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">attr</span><span class="p">)</span>
    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">BERT_LIME_attributions.json</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">w</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
    <span class="n">json</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="n">BERT_LIME_attributions</span> <span class="p">,</span> <span class="nb">file</span><span class="p">)</span>
</code></pre></div></div> <h2 id="deriving-explanations-through-attributions-with-saliency">Deriving explanations through attributions with Saliency</h2> <p>It is reasonable to use another explainability method because these methods can differ with respect to models and datasets (consider Atanasova et al. (2020)). In what follows, we will implement Saliency for our BERT model and data. The method was introduced in this paper (Simonyan et al. 2013): <a href="https://arxiv.org/abs/1312.6034" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/1312.6034</a>.</p> <p>Saliency is a gradient based explainability approach. Gradient-based methods generate saliency maps by calculating the gradient of the output with respect to the input. Unfortunately, it requires a little different set-up for our BERT model. We need to change our predict function for BERT; instead of letting it make predictions from the encodings, it needs to base its predictions on the embeddings from the final hidden states of the BERT model.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">predict_new</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="k">return</span> <span class="nc">BERT</span><span class="p">(</span><span class="n">inputs_embeds</span><span class="o">=</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div> <p>As with the Lime class we assign the forward function <code class="language-plaintext highlighter-rouge">predict_new(embeddings, mask)</code> to our Saliency object.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SALIENCY</span> <span class="o">=</span> <span class="nc">Saliency</span><span class="p">(</span><span class="n">predict_new</span><span class="p">)</span>
</code></pre></div></div> <p>If we use the embeddings for the model’s predictions, we’ll also need to handover masks as they are usually calculated based on the encodings.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">calculate_SALIENCY</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">cls</span><span class="p">):</span>
    
    <span class="n">masks</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([[</span><span class="nf">int</span><span class="p">(</span><span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">input</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    
    <span class="nb">input</span> <span class="o">=</span> <span class="n">BERT</span><span class="p">.</span><span class="n">bert</span><span class="p">.</span><span class="nf">embeddings</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

    <span class="n">attrs</span> <span class="o">=</span> <span class="n">SALIENCY</span><span class="p">.</span><span class="nf">attribute</span><span class="p">(</span>
        <span class="nb">input</span><span class="p">,</span>  <span class="c1"># Feeding the embeddings to the predict_new() function
</span>        <span class="n">target</span><span class="o">=</span><span class="n">cls</span><span class="p">,</span> 
        <span class="n">additional_forward_args</span><span class="o">=</span><span class="n">masks</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># Passing masks to predict_new()
</span>    
    <span class="c1"># L2 normalization for the attributions of Saliency
</span>    <span class="n">attributions</span> <span class="o">=</span> <span class="n">attrs</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">attributions</span>
</code></pre></div></div> <p>We can now run through the data as with LIME and derive attributions.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">BERT_SALIENCY_attributions</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">sent</span><span class="p">,</span> <span class="n">cls</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">encodings</span><span class="p">,</span> <span class="n">BERT_predictions</span><span class="p">),</span> <span class="n">total</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">encodings</span><span class="p">),</span><span class="n">desc</span><span class="o">=</span><span class="sh">"</span><span class="s">Processing</span><span class="sh">"</span><span class="p">):</span>
    <span class="n">attr</span> <span class="o">=</span> <span class="nf">calculate_SALIENCY</span><span class="p">(</span><span class="n">sent</span><span class="p">,</span> <span class="n">cls</span><span class="p">)</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">BERT_tokenizer</span><span class="p">.</span><span class="nf">convert_ids_to_tokens</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span>
    <span class="n">BERT_SALIENCY_attributions</span><span class="p">[</span><span class="n">unique_sentence_num</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">attr</span><span class="p">.</span><span class="nf">tolist</span><span class="p">())</span>
    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></div> <p>Let’s save the attributions to another file.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">BERT_SALIENCY_attributions.json</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">w</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
    <span class="n">json</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="n">BERT_SALIENCY_attributions</span><span class="p">,</span> <span class="nb">file</span><span class="p">)</span>
</code></pre></div></div> <h2 id="evaluating-the-results-human-vs-bert-rationales">Evaluating the results (human vs. BERT rationales)</h2> <p>Finally, we want to make comparisons between the tokens that were relevant for BERT’s hate detection and those that were considered as relevant by the annotators. We are interested in how well the model’s attributions align with the human rationales. We can use both explainability methods to check for the alignment.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">BERT_LIME_attributions.json</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">r</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
    <span class="n">BERT_LIME_attributions</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="nb">file</span><span class="p">)</span>

<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">BERT_SALIENCY_attributions.json</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">r</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
    <span class="n">BERT_SALIENCY_attributions</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="nb">file</span><span class="p">)</span>

<span class="c1"># Converting string keys to integers
</span><span class="n">BERT_LIME_attributions</span> <span class="o">=</span> <span class="p">{</span><span class="nf">int</span><span class="p">(</span><span class="n">k</span><span class="p">):</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">BERT_LIME_attributions</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span>
<span class="n">BERT_SALIENCY_attributions</span> <span class="o">=</span> <span class="p">{</span><span class="nf">int</span><span class="p">(</span><span class="n">k</span><span class="p">):</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">BERT_SALIENCY_attributions</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span>
</code></pre></div></div> <p>We need to convert the subword tokens into full words. This requires a customized function for the dataset. It’s not perfect, but shall suffice for most instances.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">subword_to_human_level</span><span class="p">(</span><span class="n">subwords</span><span class="p">,</span> <span class="n">subword_rationales</span><span class="p">):</span>

    <span class="n">human_level_rationales</span> <span class="o">=</span> <span class="p">[]</span> 
    <span class="n">word_rationale</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">subword</span><span class="p">,</span> <span class="n">rat</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">subwords</span><span class="p">,</span> <span class="n">subword_rationales</span><span class="p">)):</span>

        <span class="k">if</span> <span class="n">subword</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">"</span><span class="s">[CLS]</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">[SEP]</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">.</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="p">]:</span>
            <span class="k">continue</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">word_rationale</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">rat</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nf">any</span><span class="p">([</span><span class="n">subwords</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">].</span><span class="nf">startswith</span><span class="p">(</span><span class="sh">'</span><span class="s">##</span><span class="sh">'</span><span class="p">),</span>
                        <span class="n">subword</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">"</span><span class="s">#</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">],</span>
                        <span class="n">subwords</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span> 
                        <span class="n">subwords</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="sh">"</span><span class="s">#</span><span class="sh">"</span><span class="p">]):</span>
                <span class="c1"># Mean from subwords will be added to human level rationales
</span>                <span class="n">human_level_rationales</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">word_rationale</span><span class="p">))</span>
                <span class="n">word_rationale</span> <span class="o">=</span> <span class="p">[]</span>
            
    <span class="k">return</span> <span class="n">human_level_rationales</span>
</code></pre></div></div> <p>We can evaluate the alignment in terms of the Pearson correlation coefficient.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_mean_correlation</span><span class="p">(</span><span class="n">truth</span><span class="p">,</span> <span class="n">preds</span><span class="p">):</span>
       
    <span class="n">corrs</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">truth</span><span class="p">,</span> <span class="n">preds</span><span class="p">):</span>
        <span class="c1"># Zero variance check because some attributions might be only zeros
</span>        <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="nf">std</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">np</span><span class="p">.</span><span class="nf">std</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">corrs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Default to 0 correlation
</span>        <span class="k">else</span><span class="p">:</span>
            <span class="n">corrs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nf">pearsonr</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">p</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>

    <span class="n">mean_correlation</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">corrs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mean_correlation</span>  
</code></pre></div></div> <p>To calculate the correlation, we focus on instances where the model’s prediction matches the majority human annotation. Specifically, we analyze local explanations only for sentences where the model made a correct prediction, allowing us to assess how closely its rationales correspond to the average human rationales.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">human_rationales</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">correct_prediction_labels</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">BERT_rationales_LIME</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">BERT_rationales_SALIENCY</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">gold</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">avg_human_labels</span><span class="p">,</span> <span class="n">BERT_predictions</span><span class="p">):</span>

    <span class="n">sent_id</span> <span class="o">=</span> <span class="n">unique_sentence_num</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">gold</span> <span class="o">==</span> <span class="n">pred</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">gold</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">r</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">average_human_hate_rationales</span><span class="p">[</span><span class="n">sent_id</span><span class="p">].</span><span class="nf">values</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">r</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">average_human_no_hate_rationales</span><span class="p">[</span><span class="n">sent_id</span><span class="p">].</span><span class="nf">values</span><span class="p">())</span>

        <span class="n">LIME_attrs_word_level</span> <span class="o">=</span> <span class="nf">subword_to_human_level</span><span class="p">(</span><span class="n">BERT_LIME_attributions</span><span class="p">[</span><span class="n">sent_id</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">BERT_LIME_attributions</span><span class="p">[</span><span class="n">sent_id</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>

        <span class="c1"># LIME comes with positive and negative attributions; we're only interested in the positive ones because these are correlated with the model's targets
</span>        <span class="n">p_LIME</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">LIME_attrs_word_level</span><span class="p">]</span>

        <span class="n">p_SALIENCY</span> <span class="o">=</span> <span class="nf">subword_to_human_level</span><span class="p">(</span><span class="n">BERT_SALIENCY_attributions</span><span class="p">[</span><span class="n">sent_id</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">BERT_SALIENCY_attributions</span><span class="p">[</span><span class="n">sent_id</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>

        <span class="n">human_rationales</span><span class="p">[</span><span class="n">sent_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">r</span>
        <span class="n">correct_prediction_labels</span><span class="p">[</span><span class="n">sent_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">gold</span>
        <span class="n">BERT_rationales_LIME</span><span class="p">[</span><span class="n">sent_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_LIME</span>
        <span class="n">BERT_rationales_SALIENCY</span><span class="p">[</span><span class="n">sent_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_SALIENCY</span>
    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></div> <p>Finally, we can compute the Pearson correlation coefficient for LIME attributions…</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">compute_mean_correlation</span><span class="p">(</span><span class="n">human_rationales</span><span class="p">.</span><span class="nf">values</span><span class="p">(),</span> <span class="n">BERT_rationales_LIME</span><span class="p">.</span><span class="nf">values</span><span class="p">())</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="nf">float64</span><span class="p">(</span><span class="mf">0.14380772549112125</span><span class="p">)</span>
</code></pre></div></div> <p>… and for Saliency attributions.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">compute_mean_correlation</span><span class="p">(</span><span class="n">human_rationales</span><span class="p">.</span><span class="nf">values</span><span class="p">(),</span> <span class="n">BERT_rationales_SALIENCY</span><span class="p">.</span><span class="nf">values</span><span class="p">())</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="nf">float64</span><span class="p">(</span><span class="mf">0.6632999675122192</span><span class="p">)</span>
</code></pre></div></div> <p>LIME’s sampling includes an element of randomness; therefore, it would be reasonable to repeat the LIME attribution several times to arrive at average results.</p> <p>With five repititions, I get a positive correlation of 0.17 using LIME, which suggests a weak correlation between the BERT and human rationales. For Saliency, I have a much stronger colleration of 0.66. Now we can see how much influence also the chosen explainability method has. For LIME and Saliency, the BERT model has been the same. However, the BERT model appears much more aligned when seen from the perspective of the Saliency attributions.</p> <h2 id="visualizing-the-results-alignment">Visualizing the results (alignment)</h2> <p>Finally, we can visualize our results to see how the explainability methods make attributions with respect to the BERT model and its predictions.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_triple_heatmaps</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span> <span class="n">data2</span><span class="p">,</span> <span class="n">data3</span><span class="p">,</span> <span class="n">xticklabels</span><span class="p">,</span> <span class="n">title1</span><span class="p">,</span> <span class="n">title2</span><span class="p">,</span> <span class="n">title3</span><span class="p">,</span> <span class="n">save_path</span><span class="p">):</span>
    <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">ax3</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>  <span class="c1"># Creating three vertical subplots
</span>    
    <span class="c1"># Plotting the first heatmap (top) - Human rationales
</span>    <span class="n">sn</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">data1</span><span class="p">]),</span> 
               <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
               <span class="n">cmap</span><span class="o">=</span><span class="sh">"</span><span class="s">coolwarm</span><span class="sh">"</span><span class="p">,</span>
               <span class="n">xticklabels</span><span class="o">=</span><span class="n">xticklabels</span><span class="p">,</span>
               <span class="n">yticklabels</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">Human rationales</span><span class="sh">"</span><span class="p">],</span> 
               <span class="n">cbar</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
               <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">)</span>
    
    <span class="n">ax1</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="n">title1</span><span class="p">)</span>
    
    <span class="c1"># Plotting the second heatmap (middle) - Saliency attributions
</span>    <span class="n">sn</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">data2</span><span class="p">]),</span>
               <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
               <span class="n">cmap</span><span class="o">=</span><span class="sh">"</span><span class="s">coolwarm</span><span class="sh">"</span><span class="p">,</span> 
               <span class="n">xticklabels</span><span class="o">=</span><span class="n">xticklabels</span><span class="p">,</span> 
               <span class="n">yticklabels</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">Saliency</span><span class="sh">"</span><span class="p">],</span> 
               <span class="n">cbar</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
               <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">)</span>
    
    <span class="n">ax2</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="n">title2</span><span class="p">)</span>

    <span class="c1"># Plotting the third heatmap (bottom) - LIME attributions
</span>    <span class="n">sn</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">data3</span><span class="p">]),</span> 
               <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
               <span class="n">cmap</span><span class="o">=</span><span class="sh">"</span><span class="s">coolwarm</span><span class="sh">"</span><span class="p">,</span> 
               <span class="n">xticklabels</span><span class="o">=</span><span class="n">xticklabels</span><span class="p">,</span> 
               <span class="n">yticklabels</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">LIME</span><span class="sh">"</span><span class="p">],</span> 
               <span class="n">cbar</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
               <span class="n">ax</span><span class="o">=</span><span class="n">ax3</span><span class="p">)</span>
    
    <span class="n">ax3</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="n">title3</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>  <span class="c1"># Adjusting layout to prevent overlap
</span>    
    <span class="c1"># Saving the figure
</span>    <span class="k">if</span> <span class="n">save_path</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="n">save_path</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="sh">"</span><span class="s">tight</span><span class="sh">"</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span> 
    <span class="k">else</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <p>We can define a directory path here where we will save our visualizations.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dir_path_visual</span> <span class="o">=</span> <span class="sh">"</span><span class="s">visualizations</span><span class="sh">"</span>
</code></pre></div></div> <p>We loop through the rationales and attributions to create heatmaps for the words from the experiment’s sentences.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">process_and_plot_heatmaps</span><span class="p">(</span><span class="n">human_rationales</span><span class="p">,</span> <span class="n">correct_prediction_labels</span><span class="p">,</span><span class="n">BERT_rationales_SALIENCY</span><span class="p">,</span> <span class="n">BERT_rationales_LIME</span><span class="p">,</span> <span class="n">experiment_sents</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">):</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="n">output_dir</span><span class="p">):</span>
        <span class="n">os</span><span class="p">.</span><span class="nf">makedirs</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>  <span class="c1"># Creating output directory if it doesn't exist
</span>    
    <span class="k">for</span> <span class="n">sno</span> <span class="ow">in</span> <span class="n">human_rationales</span><span class="p">.</span><span class="nf">keys</span><span class="p">():</span>

        <span class="n">hate_data</span> <span class="o">=</span> <span class="n">human_rationales</span><span class="p">[</span><span class="n">sno</span><span class="p">]</span>
        <span class="n">saliency_data</span> <span class="o">=</span> <span class="n">BERT_rationales_SALIENCY</span><span class="p">[</span><span class="n">sno</span><span class="p">]</span>
        <span class="n">lime_data</span> <span class="o">=</span> <span class="n">BERT_rationales_LIME</span><span class="p">[</span><span class="n">sno</span><span class="p">]</span>

        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Plotting heatmap for rationales, saliency, and LIME for given sno: </span><span class="si">{</span><span class="n">sno</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
                        
        <span class="n">xticklabels</span> <span class="o">=</span> <span class="n">experiment_sents</span><span class="p">[</span><span class="n">sno</span><span class="p">].</span><span class="nf">strip</span><span class="p">(</span><span class="sh">'</span><span class="s">.,!?</span><span class="sh">'</span><span class="p">).</span><span class="nf">split</span><span class="p">()</span>
                            
        <span class="n">save_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="sa">f</span><span class="sh">"</span><span class="s">hate_heatmap_key_</span><span class="si">{</span><span class="n">sno</span><span class="si">}</span><span class="s">.png</span><span class="sh">"</span><span class="p">)</span>

        <span class="n">label</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Hate</span><span class="sh">"</span> <span class="k">if</span> <span class="n">correct_prediction_labels</span><span class="p">[</span><span class="n">sno</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="sh">"</span><span class="s">No Hate</span><span class="sh">"</span>
                            
        <span class="nf">plot_triple_heatmaps</span><span class="p">(</span><span class="n">hate_data</span><span class="p">,</span> 
                            <span class="n">saliency_data</span><span class="p">,</span> 
                            <span class="n">lime_data</span><span class="p">,</span> 
                            <span class="n">xticklabels</span><span class="p">,</span> 
                            <span class="n">title1</span><span class="o">=</span><span class="sa">f</span><span class="sh">"</span><span class="s">Sentence No. </span><span class="si">{</span><span class="n">sno</span><span class="si">}</span><span class="s"> Label: </span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="sh">"</span><span class="p">,</span> 
                            <span class="n">title2</span><span class="o">=</span><span class="sa">f</span><span class="sh">""</span><span class="p">,</span>
                            <span class="n">title3</span><span class="o">=</span><span class="sa">f</span><span class="sh">""</span><span class="p">,</span>
                            <span class="n">save_path</span><span class="o">=</span><span class="n">save_path</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">process_and_plot_heatmaps</span><span class="p">(</span><span class="n">human_rationales</span><span class="p">,</span> <span class="n">correct_prediction_labels</span><span class="p">,</span> <span class="n">BERT_rationales_SALIENCY</span><span class="p">,</span> <span class="n">BERT_rationales_LIME</span><span class="p">,</span> <span class="n">experiment_sents</span><span class="p">,</span> <span class="n">dir_path_visual</span><span class="p">)</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Explaining_BERT/visualization_example_2-480.webp 480w,/assets/img/Explaining_BERT/visualization_example_2-800.webp 800w,/assets/img/Explaining_BERT/visualization_example_2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/Explaining_BERT/visualization_example_2.png" class="img-fluid mx-auto d-block" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="references">References</h2> <p>Özge Alacam, Sanne Hoeken, and Sina Zarrieß. 2024. Eyes don‘t lie: Subjective hate annotation and detection with gaze. In <em>Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing</em>, pages 187–205, Miami, Florida, USA. Association for Computational Linguistics.</p> <p>Pepa Atanasova, Jakob Grue Simonsen, Christina Lioma, and Isabelle Augenstein. 2020. A diagnostic study of explainability techniques for text classification. In <em>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 3256–3274, Online. Association for Computational Linguistics.</p> <p>Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. “why should i trust you?”: Explain- ing the predictions of any classifier. In <em>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>, KDD ’16, page 1135–1144, New York, NY, USA. Association for Computing Machinery.</p> <p>Sarthak Roy, Ashish Harshvardhan, Animesh Mukherjee, and Punyajoy Saha. 2023. Probing LLMs for hate speech detection: strengths and vulnerabilities. In <em>Findings of the Association for Computational Linguistics: EMNLP 2023</em>, pages 6116–6128, Singapore. Association for Computational Linguistics.</p> <p>Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. 2013. Deep inside convolutional networks: Visualising image classification models and saliency maps. <em>CoRR</em>, abs/1312.6034.</p> <p>The <strong>Jupyter notebook</strong> for this project can be found here: <a href="https://github.com/omseeth/explaining_BERT_with_LIME_Saliency" rel="external nofollow noopener" target="_blank">https://github.com/omseeth/explaining_BERT_with_LIME_Saliency</a></p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/MCoT_sketching/">Research Directions in Multimodal Chain-of-Thought (MCoT) with Sketching</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/Tracing_early_texts/">Tracing Early Texts. A Linguistic and Historical Inquiry into Textuality</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/SoftBank_Pepper_gender_robotics/">How SoftBank’s Pepper set a positive example for gender design in robotics</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/CNN_sentiment_analysis/">How to use a Convolutional Neural Network (CNN) for text classification (sentiment analysis) with PyTorch</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/AI_ethics_primer/">AI ethics, a primer</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Maximilian Seeth. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"post-research-directions-in-multimodal-chain-of-thought-mcot-with-sketching",title:"Research Directions in Multimodal Chain-of-Thought (MCoT) with Sketching",description:"This text explores adding sketching to Multimodal Chain-of-Thought (MCoT) reasoning to enhance AI capabilities",section:"Posts",handler:()=>{window.location.href="/blog/2025/MCoT_sketching/"}},{id:"post-tracing-early-texts-a-linguistic-and-historical-inquiry-into-textuality",title:"Tracing Early Texts. A Linguistic and Historical Inquiry into Textuality",description:"Identifying a 3100 BC Mesopotamian contract as an early instance of textuality",section:"Posts",handler:()=>{window.location.href="/blog/2025/Tracing_early_texts/"}},{id:"post-how-softbank-s-pepper-set-a-positive-example-for-gender-design-in-robotics",title:"How SoftBank\u2019s Pepper set a positive example for gender design in robotics",description:"This text explores the assignment of gender to humanoids",section:"Posts",handler:()=>{window.location.href="/blog/2025/SoftBank_Pepper_gender_robotics/"}},{id:"post-explaining-bert-based-hate-speech-detection-with-lime-and-saliency-using-captum",title:"Explaining BERT-based hate speech detection with LIME and Saliency using Captum",description:"Tutorial with full code",section:"Posts",handler:()=>{window.location.href="/blog/2025/Explaining_BERT/"}},{id:"post-how-to-use-a-convolutional-neural-network-cnn-for-text-classification-sentiment-analysis-with-pytorch",title:"How to use a Convolutional Neural Network (CNN) for text classification (sentiment analysis)...",description:"Tutorial with full code",section:"Posts",handler:()=>{window.location.href="/blog/2024/CNN_sentiment_analysis/"}},{id:"post-ai-ethics-a-primer",title:"AI ethics, a primer",description:"Introduction to AI ethics that\u2019s less than 1000 words long",section:"Posts",handler:()=>{window.location.href="/blog/2024/AI_ethics_primer/"}},{id:"post-responsibility-protraction-with-remotely-controlled-combat-vehicles",title:"Responsibility Protraction with Remotely Controlled Combat Vehicles",description:"This paper examines drone warfare from an ethical perspective",section:"Posts",handler:()=>{window.location.href="/blog/2024/responspibility_protraction/"}},{id:"post-using-llms-in-syntactic-research",title:"Using LLMs in Syntactic Research",description:"Unpublished paper exploring how to use LLMs for empirical studies of syntax",section:"Posts",handler:()=>{window.location.href="/blog/2024/llms_syntactic_research/"}},{id:"post-was-ist-argument-mining",title:"Was ist Argument Mining?",description:"Eine Einf\xfchrung zum Forschungsfeld des Argument Minings",section:"Posts",handler:()=>{window.location.href="/blog/2024/argument_mining/"}},{id:"post-questioning-recursion-as-a-distinctive-feature-of-human-language",title:"Questioning Recursion as a Distinctive Feature of Human Language",description:"Putting human language into perspective with animal linguistics",section:"Posts",handler:()=>{window.location.href="/blog/2024/recursive_language/"}},{id:"post-a-deep-dive-into-transformer-models-like-gpt-and-bert-english-version",title:"A deep dive into Transformer models like GPT and BERT (English version)",description:"From neural networks to GPT and BERT, a contextualized explanation of the Transformer architecture",section:"Posts",handler:()=>{window.location.href="/blog/2024/transformer_en/"}},{id:"post-transformer-modelle-wie-gpt-und-bert-im-detail-german-version",title:"Transformer-Modelle wie GPT und BERT im Detail (German version)",description:"Vom neuronalen Netz bis zu GPT und BERT, eine kontextualisierte Erkl\xe4rung der Transformer-Architektur",section:"Posts",handler:()=>{window.location.href="/blog/2024/transformer/"}},{id:"news-happy-to-discuss-at-deutsche-telekom-39-s-ai-competence-center-https-www-telekom-com-en-company-digital-responsibility-details-artificial-intelligence-at-deutsche-telekom-1055154-responsibility-and-ai-title-why-quot-responsible-ai-quot-is-a-misnomer-abstract-the-meaning-of-responsibility-is-closely-attached-to-the-idea-of-quot-responding-quot-in-a-justified-sense-for-one-39-s-deeds-for-that-matter-responsibility-is-also-often-interpreted-as-quot-answerability-quot-the-same-holds-for-the-german-quot-verantwortung-quot-and-the-correlated-idea-of-quot-rede-und-antwort-stehen-quot-however-current-ai-cannot-be-responsible-for-different-reasons-any-existing-ai-system-up-to-date-lacks-the-capacity-to-reasonably-justify-itself-another-fundamental-aspect-of-taking-responsibility-is-also-to-accept-consequences-for-certain-actions-such-as-punishments-for-unlawful-behavior-however-a-machine-learning-system-cannot-be-punished-in-any-meaningful-way-in-short-ai-is-not-responsible-responsible-ai-is-a-misnomer-but-who-is-responsible-and-how-can-responsibility-with-ai-look-like",title:"Happy to discuss at [Deutsche Telekom&#39;s AI Competence Center](https://www.telekom.com/en/company/digital-responsibility/details/artificial-intelligence-at-deutsche-telekom-1055154) responsibility and AI. \\...",description:"",section:"News"},{id:"news-in-my-45-minutes-presentation-i-discussed-at-deutsche-telekom-39-s-ai-competence-center-https-www-telekom-com-en-company-digital-responsibility-details-artificial-intelligence-at-deutsche-telekom-1055154-llms-and-the-possibility-of-lying-title-when-moral-rules-reach-their-limits-should-llms-lie-abstract-one-of-the-most-famous-ideas-in-philosophy-is-immanuel-kant-39-s-categorical-imperative-quot-act-only-according-to-that-maxim-whereby-you-can-at-the-same-time-will-that-it-should-become-a-universal-law-quot-this-imperative-gives-us-a-concrete-solution-as-to-how-to-act-morally-it-allows-us-to-define-ethical-rules-from-non-ethical-ones-at-the-same-time-kant-is-also-known-for-proposing-that-to-not-lie-should-be-such-a-binding-moral-rule-however-we-encounter-many-situations-where-humans-lie-and-also-some-where-lying-appears-even-ethically-licensed-if-so-following-a-rule-such-as-to-not-lie-does-not-seem-to-be-always-what-we-want-from-an-ethical-point-of-view-if-we-as-humans-allow-degrees-of-variabilities-to-truth-telling-what-does-that-mean-if-we-try-to-quot-teach-quot-an-llm-to-only-produce-true-and-factual-content",title:"In my 45 minutes presentation, I discussed at [Deutsche Telekom&#39;s AI Competence Center](https://www.telekom.com/en/company/digital-responsibility/details/artificial-intelligence-at-deutsche-telekom-1055154)...",description:"",section:"News"},{id:"news-i-spoke-again-at-deutsche-telekom-39-s-ai-competence-center-https-www-telekom-com-en-company-digital-responsibility-details-artificial-intelligence-at-deutsche-telekom-1055154-about-agency-and-ai-title-agentic-ai-what-can-philosophy-teach-us-about-agency-abstract-agentic-ai-such-as-autogen-crew-ai-and-langgraph-has-recently-garnered-significant-attention-stanford-39-s-andrew-ng-renowned-for-his-neural-network-teachings-on-coursera-has-also-lauded-the-use-of-multi-agent-design-patterns-with-llms-in-the-batch-the-concept-is-straightforward-multiple-llm-powered-agents-collaborate-to-solve-problems-by-incorporating-local-memories-and-internal-reflection-capabilities-the-resulting-system-of-agents-can-be-both-powerful-and-complex-however-as-critical-ai-philosophers-we-must-ask-ourselves-do-these-agents-truly-possess-agency-that-is-the-ability-to-take-action-to-explore-the-potential-of-non-human-agents-this-talk-will-introduce-fundamental-definitions-and-conceptual-tools-to-discuss-agency-in-the-context-of-llm-agents-it-appears-that-agency-is-a-continuous-attribute-rather-than-a-categorical-one",title:"I spoke again at [Deutsche Telekom&#39;s AI Competence Center](https://www.telekom.com/en/company/digital-responsibility/details/artificial-intelligence-at-deutsche-telekom-1055154) about agency and AI....",description:"",section:"News"},{id:"news-i-39-m-presenting-a-few-machine-learning-fundamentals-for-understanding-llms-at-rewe-digital-https-www-rewe-digital-com",title:"I&#39;m presenting a few machine learning fundamentals for understanding LLMs at [Rewe Digital](https://www.rewe-digital.com/)....",description:"",section:"News"},{id:"news-my-next-talk-at-deutsche-telekom-39-s-ai-competence-center-https-www-telekom-com-en-company-digital-responsibility-details-artificial-intelligence-at-deutsche-telekom-1055154-is-scheduled-for-september-9-at-13-00-via-microsoft-teams-please-contact-me-for-the-link-title-can-we-trust-ai-abstract-trustworthiness-in-the-ai-scene-is-often-grounded-in-the-notion-of-having-a-system-that-produces-reliable-and-factually-correct-outputs-but-is-believing-that-an-output-is-true-equal-to-quot-trusting-quot-the-system-that-created-it-human-trust-is-a-complex-philosophical-and-psychological-notion-trust-may-be-a-state-of-belief-as-well-as-a-form-of-social-binding-for-example-trust-between-humans-often-implies-a-certain-degree-of-mutual-vulnerability-taking-this-into-account-is-it-even-possible-to-trust-in-machines",title:"My next talk at [Deutsche Telekom&#39;s AI Competence Center](https://www.telekom.com/en/company/digital-responsibility/details/artificial-intelligence-at-deutsche-telekom-1055154) is scheduled for September...",description:"",section:"News"},{id:"news-i-39-m-attending-the-conference-on-the-ethics-of-conversational-agents-amp-generative-ai-hosted-by-the-munich-center-for-machine-learning-https-mcml-ai",title:"\ud83d\udc40 I&#39;m attending the Conference on the Ethics of Conversational Agents &amp; Generative...",description:"",section:"News"},{id:"news-my-latest-talk-on-trust-in-ai-is-now-online-https-www-youtube-com-watch-v-phndlgwnlsu-https-www-youtube-com-watch-v-phndlgwnlsu",title:"My latest talk on Trust in AI is now online: [https://www.youtube.com/watch?v=PhNdlgwNlsU](https://www.youtube.com/watch?v=PhNdlgwNlsU) \u2728\ud83c\udfa5",description:"",section:"News"},{id:"news-back-at-rewe-digital-https-www-rewe-digital-com-introducing-the-fundamentals-of-language-models-to-a-group-of-managers",title:"Back at [Rewe Digital](https://www.rewe-digital.com/), introducing the fundamentals of language models to a group...",description:"",section:"News"},{id:"news-we-re-launching-www-dailogues-ai-https-www-dailogues-ai-our-discursive-space-around-ai",title:"We\u2019re launching [www.dailogues.ai](https://www.dailogues.ai) \ud83d\ude80, our discursive space around AI!",description:"",section:"News"},{id:"news-podcast-episode-with-me-at-dranbleiben-andre-cramer-and-i-discuss-alternative-ai-utopias-link-to-episode-https-dranbleiben-letscast-fm-episode-3-ueber-alternative-ki-utopien-https-dranbleiben-letscast-fm-episode-3-ueber-alternative-ki-utopien",title:"\ud83c\udfa7 Podcast episode with me at #DRANBLEIBEN. Andre Cramer and I discuss alternative...",description:"",section:"News"},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/omseeth","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/oseeth","_blank")}},{id:"socials-bluesky",title:"Bluesky",section:"Socials",handler:()=>{window.open("https://bsky.app/profile/maxseeth.bsky.social","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>